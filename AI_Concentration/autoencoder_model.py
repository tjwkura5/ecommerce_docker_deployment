# -*- coding: utf-8 -*-
"""autoencoder_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bVEJjjaxjjnA0MZOxHjuZqAd1ELsRvEJ
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

# Preprocessing
# Drop unnecessary columns and only keep numerical or encoded categorical features
data = data.drop(['id', 'card_id', 'customer_id', 'email', 'address_city', 'address_country', 'name_on_card'], axis=1)

# Convert categorical features to numerical using Label Encoding
label_encoder = LabelEncoder()
for column in ['address_state']:
    data[column] = label_encoder.fit_transform(data[column])

# Normalize the data
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# Split data into training and testing sets
train_data, test_data = train_test_split(data_scaled, test_size=0.2, random_state=42)

# Build the Autoencoder
input_dim = train_data.shape[1]
input_layer = Input(shape=(input_dim,))
encoded = Dense(8, activation="relu")(input_layer)
encoded = Dense(4, activation="relu")(encoded)
decoded = Dense(8, activation="relu")(encoded)
decoded = Dense(input_dim, activation="sigmoid")(decoded)

autoencoder = Model(inputs=input_layer, outputs=decoded)
autoencoder.compile(optimizer='adam', loss='mse')

# Train the Autoencoder
history = autoencoder.fit(train_data, train_data, epochs=50, batch_size=16, validation_split=0.2, shuffle=True)

# Calculate reconstruction error on test data
reconstructions = autoencoder.predict(test_data)
reconstruction_errors = np.mean(np.square(reconstructions - test_data), axis=1)

# Set a threshold for anomaly detection
threshold = np.percentile(reconstruction_errors, 95)

# Identify anomalies
anomalies = test_data[reconstruction_errors > threshold]
print("Number of anomalies detected:", len(anomalies))