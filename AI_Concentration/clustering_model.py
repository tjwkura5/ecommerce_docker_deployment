# -*- coding: utf-8 -*-
"""clustering_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eXxeDwndV7W6FDHqoGq0tGwrPYC_qCec
"""
import sqlite3
import pandas as pd

conn = sqlite3.connect('db.sqlite3')
data = pd.read_sql_query("SELECT * FROM account_stripemodel", conn)
conn.close()

# Feature Engineering
data['email_domain'] = data['email'].apply(lambda x: x.split('@')[-1])
data['card_user_count'] = data.groupby('card_number')['user_id'].transform('count')
data['customer_id_count'] = data.groupby('customer_id')['user_id'].transform('count')

# Label Encoding for categorical variables
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
data['address_country'] = label_encoder.fit_transform(data['address_country'])
data['address_state'] = label_encoder.fit_transform(data['address_state'])
data['email_domain'] = label_encoder.fit_transform(data['email_domain'])

#SECOND ML MODEL

# Define features and target variable
features = ['card_user_count', 'customer_id_count', 'address_country', 'address_state', 'exp_month', 'exp_year']
X = data[features]

from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler

# Standardize features for clustering
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# DBSCAN for anomaly detection
dbscan = DBSCAN(eps=0.5, min_samples=5)  # Tune `eps` and `min_samples` based on your data
clusters = dbscan.fit_predict(X_scaled)

# Mark outliers as potential fraud (noise points are labeled -1 by DBSCAN)
data['is_fraud'] = (clusters == -1).astype(int)

# View potential fraud cases
fraud_cases = data[data['is_fraud'] == 1]
print(fraud_cases)